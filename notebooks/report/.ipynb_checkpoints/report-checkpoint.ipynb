{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <br/>\n",
    "  <img src=\"medias/genyus-logo.png\" width=\"150px\">\n",
    "  <br/>\n",
    "  <br/>\n",
    "  <h1 align=\"center\">\n",
    "    <p align=\"center\">\n",
    "      Owen Gombas<br/>*\n",
    "      Darmanger David\n",
    "    </p>\n",
    "  </h1>\n",
    "  <h2 align=\"center\">\n",
    "    <p align=\"center\">\n",
    "      Juin 2021\n",
    "    </p>\n",
    "  </h1>\n",
    "  <br/>\n",
    "</p>\n",
    "<br><br>\n",
    "\n",
    "# 1. INTRODUCTION\n",
    "\n",
    "## 1.1 But\n",
    "\n",
    "C’est dans le cadre de notre cours de python (1242.4 PYTHON) que nous avons effectué ce projet. L’objectif du travail était de prendre en main le langage python et d’avoir une première introduction à l’analyse de données grâce aux outils fournis par le langage. Mais également une prise en main de l’utilisation de notebooks jupyter pour la mise en place du projet.\n",
    "\n",
    "En ce qui concerne le travail en lui-même, notre projet est un outil d’analyse du “vocabulaire” utilisé dans le rap francophone. Pour être plus précis, on va analyser les paroles d’un échantillon de chansons de rap francophones de ces 20-30 dernières années et les utiliser pour effectuer plusieurs statistiques. Nous avons dans un premier temps délibérément choisi de nous limiter uniquement à des musiques de rap car selon nous, c'est le genre de musique qui jouit de la plus grande diversité de langage et qui a le plus évolué dans le temps durant ces dernières années.\n",
    "\n",
    "Exemples de statistiques:\n",
    "\n",
    "    1) Afficher les mots français les plus utilisés, les mots anglais les plus utilisés mais également les mots les plus utilisés du jargon qui ne figure pas officiellement dans le dictionnaire français.\n",
    "    2) Analyse de quels artistes ont les textes les plus variés en termes de vocabulaire.\n",
    "    3) Le pourcentage d’utilisation d’un mot particulier sur l’ensemble des chansons ou encore son pourcentage d’utilisation au cours des différentes années. \n",
    "\n",
    "## 1.2 API et services utilisés\n",
    "\n",
    "En ce qui concerne le choix de notre échantillon nous avons effectué une playlist avec un total de 1847 titres différents pour un total de 109h50min de chanson en continue. Nous avons ensuite exporté le nom des musiques et les artistes qui leurs sont associés en un fichier texte, qui sera utilisé pour la récupération des données. Une partie seulement de toutes les chansons seront utilisés en raison de l’API utilisé.\n",
    "Afin de récupérer les données nécessaires au projet, nous avons besoin de : \n",
    "\n",
    "\n",
    "### 1) [Spotify](https://www.spotify.com/fr/)\n",
    "Grâce Spotify on va facilement pouvoir regrouper les chansons qui nous intéresse.\n",
    "La playlist utilisée dans le cadre du projet : https://open.spotify.com/playlist/3bp6rWaNssiLhZP431bkU7?si=a5f19a02267a4101\n",
    "\n",
    "\n",
    "### 2) [Tune My Music](https://www.tunemymusic.com/fr/Spotify-to-File.php)\n",
    "Ce site permet d'exporter une playlist dans un fichier texte simple au format:\n",
    "```\n",
    "Artist - Titre 1\n",
    "Artist - Titre 2\n",
    "Artist 2 - Titre 2.2\n",
    "```\n",
    "### 3) [Genius](https://genius.com)\n",
    "Genius est un site fournissant les paroles de musiques, et c'est l'API de ce site que l'on a utilisé afin d'obtenir des informations relative à la musique.\n",
    "\n",
    "### Fonctionnalités de l'API\n",
    "Nous avons principalement utilisé que deux fonctionnalités de l'API:\n",
    "- Recherche globale de musiques, d'artistes ou d'albums\n",
    "- Récupération des informations d'une musique, d'un artiste ou d'un album\n",
    "\n",
    "### Récupération des paroles\n",
    "Malheureusement l'API ne nous fournit pas la possibilité d'obtenir les paroles, on va devoir \"scraper\" les données avec `beautifulsoup` qui est un module python.\n",
    "\n",
    "## 1.3 Modules complémentaires\n",
    "Voici la liste des différents modules utilisés dans le projet :\n",
    "\n",
    "    - numpy (via anaconda.navigator)\n",
    "    - Pandas (via anaconda.navigator)\n",
    "    - Matplotlib (via anaconda.navigator)\n",
    "\t\n",
    "Utiliser pour l’authentification avec un token à l’API genius\n",
    "\n",
    "    - Rauth (via terminal: `pip install rauth`)\n",
    "\n",
    "Scrapping des données :\n",
    "\n",
    "    - Beautifulsoup4 (via terminal:  `pip install beautifulsoup4`)\n",
    "\n",
    "Type de graphique spécifique :\n",
    "\n",
    "    - Wordcloud (via terminal: `pip install wordcloud`)\n",
    "\n",
    "Pour avoir des composants interactifs:\n",
    "\n",
    "    - Node.js (via anaconda.navigator)\n",
    "    - Ipywidgets (via anaconda.navigator)\n",
    "\n",
    "La liste des modules utilisé dans le projet se trouvent également dans \"requirements.txt\". Pour les installer, lancez la commande `pip install -r requirements.txt` dans un terminal à la racine du projet au avec un terminal anaconda.\n",
    "\n",
    "## 1.4 Statistiques principales\n",
    "\n",
    "\n",
    "\n",
    "Donc le but général du projet est de présenter à l'aide de différentes statistiques l'utilisation la variété des mots utilisés dans les chansons de rap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. CORPS DU TRAVAIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Traitement et analyse de la liste des musiques avant récupération\n",
    "Ici le but est de traiter, nettoyer et analyser les données que l'on a en entré pour notre analyse. Ces données représentent une liste de musiques avec leur artistes (datas/songs.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paquets utilisés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppression des doublons\n",
    "Nous devons supprimer les éventuels doublons qui existent dans cette liste afin d'éviter de fausser nos résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs: pd.Series\n",
    "\n",
    "print(\"Suppression des doublons...\", \"\\n\\n\")\n",
    "\n",
    "with open(\"./datas/songs.txt\", \"r\", encoding=\"utf8\") as file:\n",
    "    # Read the songs.txt file and create a pandas Serie from it\n",
    "    songs_inputs = file.read().splitlines()\n",
    "    songs = pd.Series(songs_inputs)\n",
    "\n",
    "    print(\"Avant\", \"\\n\", songs, \"\\n\", \"...\", \"\\n\\n\")\n",
    "    \n",
    "    # Remove duplicated songs (keep the first)\n",
    "    songs.drop_duplicates(inplace=True)\n",
    "\n",
    "    print(\"Après\", \"\\n\", songs, \"\\n\", \"...\")\n",
    "\n",
    "    # Rewrite the file without the duplicated values  \n",
    "    with open(\"./datas/songs.txt\", \"w\", encoding=\"utf8\") as file:\n",
    "        file.write(\"\\n\".join(songs))\n",
    "        file.close()\n",
    "\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Représentation des artistes\n",
    "On va grouper les musiques par artistes, c'est à dire que pour chaque artiste nous faisons correspondre la liste de toutes ses musiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split each lines using \" - \" (only the first occurence)\n",
    "# \"Green Montana - Follow-moi\" => [\"Green Montana\", \"Follow-moi\"]\n",
    "df_songs = songs.str.split(\" - \", expand=True, n=1)\n",
    "df_songs.columns = [\"artist\", \"song\"]\n",
    "\n",
    "# Group the songs by artists\n",
    "df_artists_songs = df_songs.groupby(\"artist\")[\"song\"].apply(list).reset_index(name=\"songs\")\n",
    "df_artists_songs[\"songs_count\"] = df_artists_songs[\"songs\"].apply(lambda x: len(x))\n",
    "df_artists_songs.sort_values(by=\"songs_count\", inplace=True, ascending=False)\n",
    "\n",
    "df_artists_songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogramme des artistes depuis la liste (nettoyées) des musiques \n",
    "Nous pouvons maintenant afficher un histogramme depuis la liste (nettoyée) des musiques pour y voir plus clair, on affiche alors chacun de nos artistes avec son nombre de musiques que l'on possède"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artists_songs.plot(\n",
    "    kind=\"bar\",\n",
    "    x=\"artist\",\n",
    "    y=\"songs_count\",\n",
    "    figsize=(20, 10),\n",
    "    label=\"Nombre de musiques\",\n",
    "    xlabel=\"Artiste\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Récupération des informations des musiques\n",
    "Cette partie consiste à la récupération des données via l'API Genius, dans a partie précédente nous avons traité de la partie qui s'occupe des entrées de notre programme. Ici on va justement utiliser cette liste brute de musiques pour récupérer les paroles ainsi que notre information utilise relative à chacune des musiques.  \n",
    "- Les informations liées à l'artiste\n",
    "- Les informations liées à l'album où la musique apparait\n",
    "- Les parole de la musique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation\n",
    "La documentation de l'API Genius se trouve [ici](https://docs.genius.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Le scraping de données\n",
    "Malheureusement Genius ne fournit pas les paroles via son API, on doit alors ruser... La solution est la suivante:  \n",
    "- On récupère l'URL de la page affichant les paroles via car l'API nous le fournit  \n",
    "- On fait une requête GET (HTTP) à cette adresse pour récupérer toutes la page HTML affichant les paroles\n",
    "- Grâce au module BeautifulSoup on extrait uniquement le contenu de la balise HTML contenant les paroles de la musique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paquets utilisés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from typing import List, Any\n",
    "from rauth import OAuth2Service\n",
    "from bs4 import BeautifulSoup, PageElement\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classe pour la manipulation de l'API\n",
    "Une classe nous simplifie grandement les appels à l'API Genius, nous avons alors fait une classe qui sert à:\n",
    "- Faire une recherche via l'API\n",
    "- Récupérer les informations spécifiques à une musique\n",
    "- Scraper les paroles de la musique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class API:\n",
    "    \"\"\"\n",
    "    Simplify the requests to the Genius API\n",
    "    \"\"\"\n",
    "    genius: Any\n",
    "    session: Any\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        client_id: str,\n",
    "        client_secret: str,\n",
    "        authorize_url: str,\n",
    "        base_url: str,\n",
    "        token: str,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the Genius API session\n",
    "        \"\"\"\n",
    "        self.genius = OAuth2Service(\n",
    "            client_id=client_id,\n",
    "            client_secret=client_secret,\n",
    "            authorize_url=authorize_url,\n",
    "            base_url=base_url\n",
    "        )\n",
    "\n",
    "        self.session = self.genius.get_session(\n",
    "            token=token\n",
    "        )\n",
    "\n",
    "    def get_lyrics(\n",
    "        self,\n",
    "        url: str,\n",
    "        retry: bool = False,\n",
    "        wait_retry: int = 30,\n",
    "        wait: int = 0\n",
    "    ) -> dict:\n",
    "        \"\"\"\n",
    "        Get the lyrics from the Genius website\n",
    "\n",
    "        Parameters:\n",
    "            url (str): The lyrics page URL\n",
    "            retry (bool): Retry the request if it fails (default False)\n",
    "            wait_retry (int): Wait x seconds before retrying (default 30)\n",
    "            wait (int): Wait x seconds before returning the result (default 0)\n",
    "\n",
    "        Returns:\n",
    "            lyrics (str or None): The lyrics of the song\n",
    "        \"\"\"\n",
    "\n",
    "        htmlRes = requests.get(url).text\n",
    "\n",
    "        html = BeautifulSoup(htmlRes, \"html.parser\")\n",
    "\n",
    "        # Find the correct lyrics div in the html file.\n",
    "        # The classname could be \"lyrics\" or \"Lyrics__Root-sc-1ynbvzw-0\" \n",
    "        # Because the website stack probably use React or Angular with Server Side Rendering\n",
    "        lyricsDiv: PageElement = html.find(\"div\", class_=\"lyrics\")\n",
    "        if lyricsDiv == None:\n",
    "            lyricsDiv = html.find(\"div\", class_=\"Lyrics__Root-sc-1ynbvzw-0\")\n",
    "\n",
    "        if lyricsDiv != None:\n",
    "            # We do not want <br>, so we simply replace each occurence with a line return (\\n)\n",
    "            # (could be replaced by a space, because we normalize it just after)\n",
    "            for br in lyricsDiv.find_all(\"br\"):\n",
    "                br.replace_with(\"\\n\") \n",
    "\n",
    "            lyrics: str = lyricsDiv.get_text()\n",
    "\n",
    "            # We normalize the lyrics by replacing each \\n by a simple space (\" \")\n",
    "            # We do not want more than one space between each word so replace chained spaces by a single one (\"a    b\" => \"a b\")\n",
    "            # And finally we remove spaces at the beginning \n",
    "            lyrics = re.sub(r\"\\n\", \" \", lyrics)\n",
    "            lyrics = re.sub(r\"\\s{2,}\", \" \", lyrics)\n",
    "            lyrics = lyrics.strip()\n",
    "\n",
    "            # Optionnaly wait to avoid a ban from Genius's API\n",
    "            time.sleep(wait)\n",
    "\n",
    "            return lyrics\n",
    "\n",
    "        elif retry:\n",
    "            # Retry if it failed\n",
    "            print(f\"Cannot scrap lyrics... waiting {wait_retry} secondes\")\n",
    "            time.sleep(wait_retry)\n",
    "            return self.get_lyrics(url, retry, wait_retry, wait)\n",
    "\n",
    "        return None\n",
    "\n",
    "    def get_song(\n",
    "        self,\n",
    "        id: int,\n",
    "        with_lyrics: bool = False,\n",
    "        retry: bool = False,\n",
    "        wait_retry: int = 30,\n",
    "        wait: int = 0\n",
    "    ) -> dict:\n",
    "        \"\"\"\n",
    "        Get a song from the Genius API and parse it into objects (selecting only interesting fields)\n",
    "\n",
    "        Parameters:\n",
    "            id (int): The song's ID\n",
    "            with_lyrics (bool): Get the song with it's lyrics (default False)\n",
    "            retry (bool): Retry the request if the getting lyrics method failed (default False)\n",
    "            wait_retry (int): Wait x seconds if the getting lyrics method failed (default 30)\n",
    "            wait (int): Wait x seconds after the lyrics method (default 0)\n",
    "\n",
    "        Returns:\n",
    "            lyrics (dict): The song\n",
    "        \"\"\"\n",
    "\n",
    "        res = self.session.get(f\"songs/{id}?text_format=plain\").json()\n",
    "        url = res['response']['song']['url']\n",
    "        lyrics = \"\"\n",
    "\n",
    "        album: dict = None\n",
    "\n",
    "        # Extract only interesting informations about the song\n",
    "        if res['response']['song']['album']:\n",
    "            album = {\n",
    "                \"name\": res['response']['song']['album']['name'],\n",
    "                \"id\": res['response']['song']['album']['id']\n",
    "            }            \n",
    "\n",
    "        artist = {\n",
    "            \"name\": res['response']['song']['primary_artist']['name'],\n",
    "            \"id\": res['response']['song']['primary_artist']['id'],\n",
    "            \"url\": res['response']['song']['primary_artist']['url'],\n",
    "            \"image\": res['response']['song']['primary_artist']['image_url']\n",
    "        }\n",
    "\n",
    "        song = {\n",
    "            \"id\": res['response']['song']['id'],\n",
    "            \"name\": res['response']['song']['title'],\n",
    "            \"album\": album,\n",
    "            \"artist\": artist,\n",
    "            \"image\": res['response']['song']['header_image_url'],\n",
    "            \"url\": url,\n",
    "            \"original_lyrics\": lyrics,\n",
    "            \"date\": datetime.strptime(\n",
    "                res['response']['song']['release_date'] or \"1900-01-01\", \"%Y-%m-%d\").isoformat()\n",
    "        }\n",
    "\n",
    "        if with_lyrics:\n",
    "            lyrics = self.get_lyrics(url, retry, wait_retry, wait)\n",
    "\n",
    "        if lyrics != None:\n",
    "            song[\"original_lyrics\"] = lyrics\n",
    "\n",
    "        return song\n",
    "\n",
    "    def search(self, query: str) -> List[dict]:\n",
    "        \"\"\"\n",
    "        Search for an album, artist, song in the Genius API\n",
    "\n",
    "        Parameters:\n",
    "            query (str): The search query\n",
    "\n",
    "        Returns:\n",
    "            Results (List[dict]): The provided results\n",
    "        \"\"\"\n",
    "\n",
    "        search = self.session.get(f\"search?q={query}\").json()\n",
    "        hits = search['response']['hits']\n",
    "        results: List[dict] = []\n",
    "\n",
    "        for hit in hits:\n",
    "        # Extract only interesting informations about the searched song\n",
    "            hitResult = hit['result']\n",
    "\n",
    "            artist = {\n",
    "                \"name\": hitResult['primary_artist']['name'],\n",
    "                \"id\": hitResult['primary_artist']['id'],\n",
    "                \"image\": hitResult['primary_artist']['image_url'],\n",
    "                \"url\": hitResult['primary_artist']['url']\n",
    "            }\n",
    "\n",
    "            search = {\n",
    "                \"title\": hitResult['title'],\n",
    "                \"url\": hitResult['url'],\n",
    "                \"artist\": artist,\n",
    "                \"id\": hitResult['id']\n",
    "            }\n",
    "\n",
    "            results.append(search)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def print_json(content: str):\n",
    "        print(json.dumps(content, indent=2, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authentification à l'API\n",
    "Afin de faire des requêtes à l'API nous devons nous authentifier avec un token OAuth  \n",
    "Ce token peut être généré à l'adresse suivante: [https://genius.com/api-clients](https://genius.com/api-clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the demo we let the tokens on purpose but we should avoid doing that\n",
    "api = API(\n",
    "    client_id=\"xAP0jvOkLrC3eAjwE4iCeY5BdSrgH7qKUQyh8907-2fGiAGYEHJMNhtFglSLznAq\",\n",
    "    client_secret=\"WIVq7t1Jq5uaN0OkYCPzhVMr4mt_d-ufoq5fSC6qmyUaxodx5kZ4bS56J87C-LXGRqeeXp9nFpjgrgPtZ_8niA\",\n",
    "    authorize_url=\"https://api.genius.com/oauth/authorize\",\n",
    "    base_url=\"https://api.genius.com/\",\n",
    "    token=\"qfhBonIalyiGK0DcsHmg3-heXf485c1dSV-gOM3ZU4Wn3eD-6-pKjESnhYg4kJ1y\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupération d'une musique avec l'API Genius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song = api.get_song(1)\n",
    "API.print_json(song)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche d'une musique avec l'API Genius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = api.search(\"damso\")\n",
    "API.print_json(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupération des paroles d'une musique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = api.get_lyrics(song[\"url\"])\n",
    "lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Scraping des données\n",
    "Récupération de toutes les musiques d'un à partir du fichier contenant les musiques (datas/songs.txt)  \n",
    "**Le code n'est pas exécuté (la fonction `scrap` n'est pas appelée, car commentée), cette opération peut durer plusieurs heures. Nous avons déjà effectué ce scraping afin de nourrir notre fichier songs.json, qui représente entre-autre notre base de données des musiques**\n",
    "\n",
    "Comme nous l'avons déjà détaillé, les opérations suivantes pour chacune des musiques sont effectuées pour scraper les paroles\n",
    "\n",
    "- On utilise la méthode de recherche de la classe API (`api.search`)\n",
    "\n",
    "- Si des résultats sont donnés, on opère uniquement sur le premier résultat (qui est probablement celui qui nous intéresse) on récupéré les informations de ce résultat (\"hit\") qui représente la musique pas dans sa totalité, c'est la raison pour laquelle on fait cette opération  (`api.get_song`)  \n",
    "Cette opération va également récupérer les paroles de la musique directement (grâce aux argument passés à la méthode)\n",
    "\n",
    "- On ajoute cete musique dans une liste de résultats et on exporte cette liste en JSON dans le fichier `api_songs.json`\n",
    "\n",
    "> On exporte le fichier à chaque itération car si la boucle est interrompue par une erreur on peut quand même récupérer la liste des musiques qui ont été récupérées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path: str = \"./datas/songs.txt\"\n",
    "output_path: str = \"./datas/api_songs.json\"\n",
    "\n",
    "def scrap():\n",
    "    with open(input_path, \"r\", encoding=\"utf8\") as file:\n",
    "        songs_inputs = file.read().splitlines()\n",
    "        songs: List[str] = []\n",
    "      \n",
    "        for index, song_input in enumerate(songs_inputs, start=1):\n",
    "            # Search for a song with a query for example: \"Green Montana - CALIFORNIA\"\n",
    "            results = api.search(song_input)\n",
    "\n",
    "            # Retrieve all the songs informations and lyrics of the first result\n",
    "            # (the first result is the one that we are interested in)\n",
    "            if len(results) > 0:\n",
    "                song = api.get_song(results[0][\"id\"], True, True, 0, 0)\n",
    "                songs.append(song)\n",
    "\n",
    "                print(f\"{index / len(songs_inputs) * 100:.2f}%     {song['artist']['name']} - {song['name']}\")\n",
    "            \n",
    "            # Write the file in JSON format at api_songs.json\n",
    "            with open(output_path, \"w\", encoding=\"utf8\") as output:\n",
    "                output.write(\n",
    "                    json.dumps(\n",
    "                        songs,\n",
    "                        default=lambda obj: obj.__dict__,\n",
    "                        ensure_ascii=False\n",
    "                    )\n",
    "                )\n",
    "                output.close()\n",
    "        file.close()\n",
    "\n",
    "    print(\"Le fichier JSON contenant les musiques a été écrit dans: \", output_path)\n",
    "\n",
    "# We avoid calling this function because it can easily last few hours\n",
    "# The result of our songs list is already in the file api_songs.json\n",
    "# scrap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Clean des sons après récupération\n",
    "On ne peut pas se fier complètement à la recherche de l'API Genius, pour deux raisons:\n",
    "\n",
    "- Le son peut potentiellement ne pas exister dans la base de données de Genius\n",
    "\n",
    "- Le premier résultat n'est pas forcément le bon, on proposition d'amélioration aurait pu d'être de parcourir tous les résultats d'une recherche et vérifier si la musique recherchée n'apparait pas comme le deuxième, troisième, ..., résultat\n",
    "\n",
    "Pour ces raisons nous allons filtrer que les musique qui étaient bel et bien dans notre liste de musique au départ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paquets utilisés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application du tri\n",
    "En entrée on va prendre le fichier comportant la liste des musiques que l'on a scrapé auparavant (`api_songs.json`) et on va en premier temps vérifier, pour chacune des musiques, qu'elle existant au départ dans notre liste de sons brute (`songs.txt`) en recréant un champ `Artiste - Titre de musique` à partir des informations réel de la musique. En deuxième temps, nous allons simplement supprimer tous les potentiels doublons qui pourrait apparaitre dans notre liste. Pour finalement afficher le pourcentage de musique que l'on peut exploiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"./datas/api_songs.json\"\n",
    "output_path = \"./datas/songs.json\"\n",
    "\n",
    "songs = pd.read_json(input_path)\n",
    "inputs: pd.Series\n",
    "\n",
    "with open(\"./datas/songs.txt\", \"r\", encoding=\"utf8\") as file:\n",
    "    inputs = pd.Series(file.read().lower().splitlines())\n",
    "    file.close()\n",
    "\n",
    "# We recreate the field \"Artist - Title\" in the DataFrame\n",
    "songs[\"artist_name\"] = songs['artist'].apply(pd.Series)[\"name\"]\n",
    "songs[\"query\"] = songs['artist_name'].str.lower() + \" - \" + songs['name'].str.lower()\n",
    "\n",
    "# We verify that the song exists in the file songs.txt\n",
    "songs[\"is_in_inputs\"] = songs[\"query\"].isin(inputs)\n",
    "\n",
    "# We filter the songs and remove the songs that aren't the the file songs.txt\n",
    "songs = songs[songs[\"is_in_inputs\"] == True]\n",
    "\n",
    "# We remove the duplicated songs\n",
    "songs.drop_duplicates(subset=[\"id\"], inplace=True)\n",
    "\n",
    "del songs[\"is_in_inputs\"]\n",
    "del songs[\"artist_name\"]\n",
    "\n",
    "print(f\"Avec {len(inputs)} musiques, Genius a fournit {len(songs)} musiques de façon correcte\")\n",
    "print(f\"Nous gardons alors {len(songs) / len(inputs) * 100:.2f}% de nos musiques pour la suite\")\n",
    "\n",
    "songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Création de plusieurs champs dérivé des paroles originales\n",
    "Nous allons avoir besoin de plusieurs variations des paroles afin de procéder à nos statistiques.  \n",
    "Notamment pour analyser grâce un dictionnaire de mots d'une langue les mots existant dans cette langue (`lyrics_keywords`)\n",
    "\n",
    "### `original_lyrics`\n",
    "Les paroles originales, celles récupérées sur le site [genius.com](https://genius.com)\n",
    "\n",
    "### `lyrics`\n",
    "Les paroles sans: `[Couplet]`, `mot94`, `34`, `  `\n",
    "- Supprime les accolades et leur contenu \"\\[...]\"\n",
    "- Supprime toutes les parenthèses et leur contenu\n",
    "- Supprime tous ce qui n'est pas une lettre, une apostrophe ou un tirait (a-Z, ', -)\n",
    "- Supprime les lettres seules \"abc d efg\" => \"abc efg\"\n",
    "- Remplace plusieurs espaces par un seul \"abc   def\" => \"abc def\"\n",
    "\n",
    "### `lyrics_keywords`\n",
    "Les paroles utilisées pour être comparée avec un dictionnaire, elles sont normalisées à leur forme la plus simple, effectue le même nettoyage que pour le champ `lyrics` mais sans les mot basé sur des apostrophes, les apostrophes, les tirait, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Remove: \"[...]\"\n",
    "# 2. Remove all the brackets and their contents \"(...)\"\n",
    "# 3. Remove everything that is not a letter (a-Z) a word letter a single quote \"'\" or a \"-\"\n",
    "# 4. Remove alone letters \"abc d efg\" => \"abc efg\"\n",
    "# 5. Replace chained spaces by a single one \"abc   def\" => \"abc def\"\n",
    "def clean_lyrics(lyrics: str):\n",
    "    lyrics = re.sub(r\"\\([^()]*\\)\", \" \", lyrics, flags=re.M | re.I)\n",
    "    lyrics = re.sub(r\"\\s*\\[(.*?)\\]\\s*\", \" \", lyrics, flags=re.M | re.I)\n",
    "    lyrics = re.sub(r\"[^a-zA-Z \\w ' -]\", \" \", lyrics, flags=re.M | re.I)\n",
    "    lyrics = re.sub(r\"\\w*\\d\\w*\", \"\", lyrics, flags=re.M | re.I)\n",
    "    lyrics = re.sub(r\"\\s{2,}\", \" \", lyrics, flags=re.M | re.I)\n",
    "    lyrics = lyrics.strip().lower()\n",
    "\n",
    "    return lyrics\n",
    "\n",
    "# Clean the lyrics like clean_lyrics does\n",
    "# but it remove also the letters/words that can't be compared to a dictionnary\n",
    "def clean_lyrics_keywords(lyrics: str):\n",
    "    lyrics = clean_lyrics(lyrics)\n",
    "    lyrics = re.sub(r\"(^|\\s)(qu'|j'|l'|t'|c'|t'|d'|s'|n'|y'|m')*\", \" \", lyrics, flags=re.M | re.I)\n",
    "    lyrics = re.sub(r\"'(\\s|$)\", \" \", lyrics, flags=re.M | re.I)\n",
    "    lyrics = re.sub(r\"(\\s|^)'\", \" \", lyrics, flags=re.M | re.I)\n",
    "    lyrics = re.sub(r\"-(\\s|$)\", \" \", lyrics, flags=re.M | re.I)\n",
    "    lyrics = re.sub(r\"(\\s|^)-\", \" \", lyrics, flags=re.M | re.I)\n",
    "    lyrics = re.sub(r\"(^| ).(( ).)*( |$)\", \" \", lyrics, flags=re.M | re.I)\n",
    "    lyrics = re.sub(r\"\\s{2,}\", \" \", lyrics, flags=re.M | re.I)\n",
    "    lyrics = lyrics.strip().lower()\n",
    "\n",
    "    return lyrics\n",
    "\n",
    "songs[\"lyrics\"] = songs[\"original_lyrics\"].apply(clean_lyrics)\n",
    "songs[\"lyrics_keywords\"] = songs[\"original_lyrics\"].apply(clean_lyrics_keywords)\n",
    "\n",
    "songs_json = songs.to_json(force_ascii=False, orient=\"records\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf8\") as file:\n",
    "    file.write(songs_json)\n",
    "    file.close()\n",
    "\n",
    "print(\"Le fichier JSON nettoyé a été écrit dans: \", output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Analyse des mots avec des dictionnaires de langues\n",
    "Nous passons à la partie des statistiques, on va afficher les mots créer dans le rap qui ne figure pas dans le dictionnaire français, ceci a pour but de faire ressortir les mots du verlan ainsi que les mots créer par ce genre musical (argots, créations, mot d'autres origines, etc.…). Nous allons également analyser les anglicismes les plus utilisés pour finir par afficher les mots français étant les plus employés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paquets utilisés\n",
    "On aura besoin des librairies externe: \n",
    "- [numpy](https://numpy.org/)\n",
    "- [pandas](https://pandas.pydata.org/)\n",
    "- [matplotlib](https://matplotlib.org/)\n",
    "- [wordcloud](https://amueller.github.io/word_cloud/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as ipw\n",
    "from wordcloud import WordCloud\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ouverture des fichiers contenant les données à utiliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs: pd.DataFrame\n",
    "french: pd.Series\n",
    "english: pd.Series\n",
    "\n",
    "songs = pd.read_json(\"./datas/songs.json\")\n",
    "\n",
    "with open(\"./datas/french.txt\", \"r\", encoding=\"utf8\") as file:\n",
    "        french = pd.Series(file.read().lower().splitlines())\n",
    "        file.close()\n",
    "\n",
    "# Generated with http://app.aspell.net/create\n",
    "with open(\"./datas/english.txt\", \"r\", encoding=\"utf8\") as file:\n",
    "        english = pd.Series(file.read().lower().splitlines())\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sélection et manipulation des données afin de pouvoir les utiliser\n",
    "On va simplement comparer tous les mots que l'on possède avec le champ `lyrics_keywords`, compter leur nombre d'apparition et filtrer cette liste de musiques en vérifiant que ces mots ne figurent pas dans le dictionnaire français et anglais car on ne veut pas afficher les anglicismes ici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group all the words of all the songs in a single pd.Serie\n",
    "words: pd.Series = songs[\"lyrics_keywords\"].apply(lambda x: x.split(\" \")).explode()\n",
    "\n",
    "# Number of every differents words in all lyrics\n",
    "all_words_count=len(words)\n",
    "\n",
    "# Count all the words in this array\n",
    "occurences: pd.Series = words.value_counts()\n",
    "\n",
    "# Create a Dataframe that contains the number of occurence\n",
    "# and if the word is inside the french dictionary\n",
    "data = {\n",
    "    \"count\": occurences,\n",
    "    \"is_french\": occurences.index.isin(french),\n",
    "    \"is_english\": occurences.index.isin(english)\n",
    "}\n",
    "\n",
    "description = pd.DataFrame(\n",
    "    data=data,\n",
    "    columns=[\"count\", \"is_french\", \"is_english\"],\n",
    "    index=occurences.index\n",
    ")\n",
    "\n",
    "#Select all the words and their count\n",
    "words_count = pd.Series(description[\"count\"], description.index)\n",
    "\n",
    "# Select only the words that aren't french\n",
    "not_french = description[description[\"is_french\"] == False]\n",
    "not_french = not_french[not_french[\"is_english\"] == False]\n",
    "\n",
    "frequency = pd.Series(not_french[\"count\"], index=not_french.index)\n",
    "\n",
    "with open(\"./datas/not_french.csv\", \"w\", encoding=\"utf8\") as f:\n",
    "        f.write(frequency.to_csv())\n",
    "        f.close()\n",
    "\n",
    "not_french"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ceci est la liste des mots de figurant pas dans le dictionnaire français avec leurs occurrences (globale, parmi toutes les musiques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. STATISTIQUES SUR L'UTILISATION DES MOTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Recherche d'un mot particulier et pourcentage\n",
    "Pour jouer un peu avec la liste créée ci-dessus vous pouvez entrer un mot dans le champ ci-dessus afin de voir son nombre d'occurrences dans les paroles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Textbox creation\n",
    "word_textbox = ipw.Text(value=\"\", placeholder=\"Search word\", description=\"Word to count:\", disabled=False)\n",
    "\n",
    "# Function called when the button is clicked\n",
    "def textbox_changed(word: str):\n",
    "    word_searched = word.lower().strip()\n",
    "\n",
    "    if word_searched in words_count:\n",
    "        #number of times used\n",
    "        print(f\"Le mot \\\"{word_searched}\\\" est utilisé {words_count[word_searched]} fois dans toutes les paroles\\n\")\n",
    "        #percentage of use\n",
    "        percentage_used_word = round(words_count[word_searched] / all_words_count * 100, 2)\n",
    "        print(f\"Pourcentage d'utilisation: {percentage_used_word}%\")\n",
    "    else:\n",
    "        print(f\"Le mot \\\"{word_searched}\\\" ne se trouve pas dans les paroles\")\n",
    "\n",
    "# Button interaction\n",
    "ipw.interact_manual(textbox_changed, word=word_textbox.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Les mots ne figurant pas dans le dictionnaire français (ni anglais)\n",
    "### L'argot, le ver-lan, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordCloud, plus le mot est grand, plus il est utilisé\n",
    "Voici une représentation des 50 mots en \"word-cloud\" les plus utilisés ne figurant pas dans le dictionnaire français\n",
    "\n",
    "Pour cette représentation on a utilisé le module [WordCloud](https://amueller.github.io/word_cloud/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(\n",
    "    font_path=\"./medias/poppins.ttf\",\n",
    "    background_color=\"white\",\n",
    "    width=1600,\n",
    "    height=800,\n",
    "    max_words=50\n",
    ").generate_from_frequencies(frequency.to_dict())\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogramme des mots\n",
    "Une autre représentation possible de ces mots est en histogramme, voici alors les 30 mots les plus utilisés avec leurs nombres d'occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency.head(30).plot(\n",
    "    kind=\"bar\",\n",
    "    figsize=(14, 7),\n",
    "    ylabel=\"Nombre d'utilisation\",\n",
    "    xlabel=\"Mot\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Les anglicismes\n",
    "On va analyser les mots les plus utilisés provenant de l'anglais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_words = description[description[\"is_french\"] == False]\n",
    "english_words = english_words[english_words[\"is_english\"] == True]\n",
    "\n",
    "frequency = pd.Series(english_words[\"count\"], index=english_words.index)\n",
    "\n",
    "with open(\"./datas/english_words.csv\", \"w\", encoding=\"utf8\") as f:\n",
    "        f.write(frequency.to_csv())\n",
    "        f.close()\n",
    "\n",
    "english_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordCloud, plus le mot est grand, plus il est utilisé\n",
    "Voici une représentation des 50 mots en \"word-cloud\" les plus utilisés figurant dans le dictionnaire anglais\n",
    "\n",
    "Pour cette représentation on a utilisé le module [WordCloud](https://amueller.github.io/word_cloud/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(\n",
    "    font_path=\"./medias/poppins.ttf\",\n",
    "    background_color=\"white\",\n",
    "    width=1600,\n",
    "    height=800,\n",
    "    max_words=50\n",
    ").generate_from_frequencies(frequency.to_dict())\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogramme des mots\n",
    "Une autre représentation possible de ces mots est en histogramme, voici alors les 30 mots les plus utilisés avec leurs nombres d'occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency.head(30).plot(\n",
    "    kind=\"bar\",\n",
    "    figsize=(14, 7),\n",
    "    ylabel=\"Nombre d'utilisation\",\n",
    "    xlabel=\"Mot\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Le \"vrai\" français\n",
    "On va afficher les mots les plus utilisés figurant uniquement dans le dictionnaire français"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "french_words = description[description[\"is_french\"] == True]\n",
    "\n",
    "frequency = pd.Series(french_words[\"count\"], index=french_words.index)\n",
    "\n",
    "with open(\"./datas/french_words.csv\", \"w\", encoding=\"utf8\") as f:\n",
    "        f.write(frequency.to_csv())\n",
    "        f.close()\n",
    "\n",
    "french_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordCloud, plus le mot est grand, plus il est utilisé\n",
    "Voici une représentation en \"word-cloud\" des 50 mots les plus utilisés figurant dans le dictionnaire français\n",
    "\n",
    "Pour cette représentation on a utilisé le module [WordCloud](https://amueller.github.io/word_cloud/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(\n",
    "    font_path=\"./medias/poppins.ttf\",\n",
    "    background_color=\"white\",\n",
    "    width=1600,\n",
    "    height=800,\n",
    "    max_words=50\n",
    ").generate_from_frequencies(frequency.to_dict())\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogramme\n",
    "Une autre représentation possible de ces mots est en histogramme, voici alors les 30 mots les plus utilisés avec leurs nombres d'occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency.head(30).plot(\n",
    "    kind=\"bar\",\n",
    "    figsize=(14, 7),\n",
    "    ylabel=\"Nombre d'utilisation\",\n",
    "    xlabel=\"Mot\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Répartition du language\n",
    "Finalement, il est intéressant d'afficher grâce à un pie chart\", la répartition de ces langues/langages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of words by language\n",
    "french_words_count = len(description[description[\"is_french\"] == True])\n",
    "english_words_count = len(english_words)\n",
    "other_words_count = len(not_french)\n",
    "\n",
    "datas = [french_words_count, english_words_count, other_words_count]\n",
    "labels = [\"French\", \"English\", \"Other (slang)\"]\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.title(\"Usage of language\")\n",
    "\n",
    "plt.pie(datas, labels=labels, autopct='% 1.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. STATISTIQUES SUR LES ARTISTES\n",
    "Pour le moment on n'a fait que des traitements sur les musiques sans prendre en compte l'artiste, ici on va justement traiter de ceux-ci.\n",
    "\n",
    "La difficulté est alors de \"retourner la chaussette\", c'est à dire de regrouper toutes les musiques par leur artiste ou lieu d'avoir une grande liste de musiques non groupée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paquets utilisés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as ipw\n",
    "from wordcloud import WordCloud\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Regroupement des musiques par artistes\n",
    "Cette opération est plutôt fastidieuse, on va premièrement créer un champ contenant toutes les informations de l'artiste (dictionnaire) qui va nous permettre de grouper les musiques (par ce champs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = pd.read_json(\"./datas/songs.json\")\n",
    "\n",
    "songs[\"lyrics_list\"] = songs[\"lyrics\"].apply(lambda x: x.split(\" \"))\n",
    "\n",
    "artist_as_dataframe = songs['artist'].apply(pd.Series)\n",
    "artist_as_dataframe.rename(columns=lambda x: \"artist_\" + str(x), inplace=True)\n",
    "\n",
    "album_as_dataframe = songs['album'].apply(pd.Series)\n",
    "album_as_dataframe.rename(columns=lambda x: \"album_\" + str(x), inplace=True)\n",
    "\n",
    "songs = pd.concat([\n",
    "    artist_as_dataframe,\n",
    "    album_as_dataframe,\n",
    "    songs\n",
    "], axis=1)\n",
    "\n",
    "songs[\"artist_dict\"] = songs[\"artist\"].apply(lambda x: json.dumps(x))\n",
    "\n",
    "songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_songs = pd.DataFrame(songs.groupby(\"artist_dict\").apply(lambda g: g.to_dict(\"records\"))).reset_index()\n",
    "\n",
    "artists_songs.columns = [\"artist\", \"songs\"]\n",
    "\n",
    "artists_songs[\"artist\"] = artists_songs[\"artist\"].apply(lambda x: json.loads(x))\n",
    "\n",
    "artists = pd.DataFrame.from_dict(artists_songs[\"artist\"].to_dict(), orient=\"index\")\n",
    "\n",
    "artists[\"songs\"] = artists_songs[\"songs\"]\n",
    "artists[\"songs_count\"] = artists_songs[\"songs\"].map(lambda x: len(x))\n",
    "\n",
    "artists = artists.sort_values(\"songs_count\", ascending=False)\n",
    "\n",
    "artists[\"artist_id\"] = artists[\"name\"].str.lower()\n",
    "artists.set_index(\"artist_id\", inplace=True)\n",
    "\n",
    "artists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient ici la liste de tous les artistes avec un champs contenant la liste de ses musiques sous forme de dictionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Représentation des pertes du au nettoyage des musiques au niveau des artistes\n",
    "Grâce à ce groupement par artiste on va pouvoir représenter graphiquement les pertes engendrées par le nettoyage du fichier `api_songs.json`\n",
    "\n",
    "La barre bleue montre le nombre de musiques que l'on voulait récupérer de base, en orange c'est ce que l'on a pu obtenir après le nettoyage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_inputs: pd.Series\n",
    "\n",
    "with open(\"./datas/songs.txt\", \"r\", encoding=\"utf8\") as file:\n",
    "    songs_inputs = pd.Series(file.read().splitlines())\n",
    "    file.close()\n",
    "\n",
    "songs = songs_inputs.str.split(\" - \", expand=True, n=1)\n",
    "songs.columns = [\"artist\", \"song\"]\n",
    "\n",
    "# Group the songs by artists\n",
    "artists_comparaison = songs.groupby(\"artist\")[\"song\"].apply(list).reset_index(name=\"songs\")\n",
    "artists_comparaison[\"songs_count\"] = artists_comparaison[\"songs\"].apply(lambda x: len(x))\n",
    "artists_comparaison.sort_values(by=\"songs_count\", inplace=True, ascending=False)\n",
    "\n",
    "artists_comparaison[\"artist_id\"] = artists_comparaison[\"artist\"].str.lower()\n",
    "artists_comparaison.set_index(\"artist_id\", inplace=True)\n",
    "\n",
    "artists_comparaison[\"songs_count_after_clean\"] = artists[\"songs_count\"]\n",
    "artists_comparaison = artists_comparaison[[\"artist\", \"songs_count\", \"songs_count_after_clean\"]]\n",
    "\n",
    "# Display the histogram\n",
    "artists_comparaison.columns = [\"Artiste\", \"Nombre de musiques initial\", \"Nombre de musiques après filtre\"]\n",
    "artists_comparaison.plot.bar(\n",
    "    x=\"Artiste\",\n",
    "    figsize=(25, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Calcul du pourcentage de répétition\n",
    "Une statistique plutôt intéressante est de mesurer la richesse du vocabulaire des artistes en montrant lesquels se répètent le plus dans leurs paroles via un histogramme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_words(song: dict):\n",
    "    songs_count = len(song)\n",
    "\n",
    "    song_df = pd.DataFrame(song)\n",
    "    words = song_df[\"lyrics\"].map(lambda x: x.split(\" \")).explode().to_list()\n",
    "\n",
    "    return words\n",
    "\n",
    "def select_unique_words(words: list):\n",
    "    return pd.Series(words).drop_duplicates().to_list()\n",
    "\n",
    "# All the used words of the artist\n",
    "artists[\"words\"] = artists[\"songs\"].map(select_words)\n",
    "artists[\"words_count\"] = artists[\"words\"].map(lambda x: len(x))\n",
    "\n",
    "# All the used words os the artist but without duplications\n",
    "artists[\"unique_words\"] = artists[\"words\"].map(select_unique_words)\n",
    "artists[\"unique_words_count\"] = artists[\"unique_words\"].map(lambda x: len(x))\n",
    "\n",
    "# Count the number of repetition\n",
    "artists[\"reptition_count\"] = artists[\"words_count\"] - artists[\"unique_words_count\"]\n",
    "\n",
    "# Make a percentage of the repetitions\n",
    "artists[\"repetition_percentage\"] = artists[\"reptition_count\"] / artists[\"words_count\"] * 100\n",
    "\n",
    "artists.sort_values(by=\"repetition_percentage\", inplace=True)\n",
    "\n",
    "artists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Classement des artistes se répétant du moins au plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists.plot(\n",
    "    kind=\"bar\",\n",
    "    x=\"name\",\n",
    "    y=\"repetition_percentage\",\n",
    "    figsize=(20, 10),\n",
    "    xlabel=\"Artiste\",\n",
    "    label=\"Pourcentage de répétition\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. STATISTIQUES DANS LE TEMPS\n",
    "Nous récupérons également une date sur chacune des musiques, il est alors intéressant d'exploiter cette donnée afin de relever l'évolution du langage dans le temps.\n",
    "\n",
    "Comme représentation nous avons choisi de faire deux histogrammes:\n",
    "- Un premier avec comme axe x les années et en axe y la moyenne du pourcentage d'utilisation du mot **par musique** durant l'année.\n",
    "\n",
    "- Un deuxième avec comme axe x les années et en axe y le nombre de musiques utilisant ce mot durant l'année\n",
    "\n",
    "Cette façon de représenter cette donnée statistique peut toujours être contestée, il y'a effectivement plusieurs manières de faire ressortir cette donnée. Mais celle-ci à l'avantage d'être cohérente. Prenons pour exemple le mot \"le\", statistiquement il est juste de se dire que l'utilisation de ce mot ne varie pas d'années en années car c'est un mot que l'on peut qualifier d'indispensable pour composer un texte. Et notre méthode garantie cette cohérence. Ainsi, si un artiste utilise un mot beaucoup de fois sur une musique cela peut nous induire en erreur par exemple.\n",
    "\n",
    "Initialement notre réprésentation était plutôt incomplète, en axe y on représentais le pourcentage d'utilisation du mot durant toute l'année sans prendre en compte son appartenance à une certaine musique. Ce qui peut causer des erreurs d'interpétation du graphique.\n",
    "\n",
    "Cette statistique, est très intéressantes en dehors de l'aspect mathématique de la chose. On peut étudier, grâce à ça: l'évolution des mentalités, analyser les tendances / modes, ainsi que de tracker la création de certains mots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paquets utilisés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as ipw\n",
    "from wordcloud import WordCloud\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Regroupement des mots par années"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = pd.read_json(\"./datas/songs.json\")\n",
    "\n",
    "songs[\"year\"] = songs[\"date\"].map(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S\").year)\n",
    "\n",
    "songs.sort_values(\"year\", ascending=False, inplace=True)\n",
    "\n",
    "songs[\"words\"] = songs[\"lyrics_keywords\"].map(lambda x: x.split(\" \"))\n",
    "\n",
    "songs = songs.groupby(\"year\")[\"lyrics_keywords\"].apply(list)\n",
    "songs = songs.reset_index()\n",
    "\n",
    "def split_keyword(keywords_list: List[str]):\n",
    "    return [keywords.split(\" \") for keywords in keywords_list]\n",
    "songs[\"lyrics_keywords\"] = songs[\"lyrics_keywords\"].apply(split_keyword)\n",
    "\n",
    "songs[\"songs_count\"] = songs[\"lyrics_keywords\"].map(lambda x: len(x))\n",
    "\n",
    "songs = songs[songs[\"year\"] > 1900]\n",
    "\n",
    "songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Représentation du nombre de nos musiques par année"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs.plot(\n",
    "    kind=\"bar\",\n",
    "    x=\"year\",\n",
    "    y=\"songs_count\",\n",
    "    figsize=(14, 7),\n",
    "    xlabel=\"Année\",\n",
    "    label=\"Nombre de musiques\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Affichages de l'utilisation d'un mot par années\n",
    "Ici vous pouvez simplement taper un mot afin d'afficher les deux histogrammes mentionnés au début du chapitre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Textbox creation\n",
    "word_textbox = ipw.Text(value=\"\", placeholder=\"Search word\", description=\"Word to count:\", disabled=False)\n",
    "\n",
    "songs_count: pd.DataFrame\n",
    "searched_word: str\n",
    "\n",
    "# Here we calculate, for each songs, the percentage of usage of the word\n",
    "def percentage_usage_per_song(word: str, words: List[List[str]]):\n",
    "    words_list = pd.Series(words)\n",
    "\n",
    "    def count_percentage(words: List[str]):\n",
    "        words = pd.Series(words)\n",
    "        return len(words[words == word]) / len(words) * 100\n",
    "\n",
    "    percentage_usage_per_song = words_list.map(count_percentage)\n",
    "\n",
    "    return percentage_usage_per_song\n",
    "\n",
    "# We want to count how many songs use the word\n",
    "def count_songs(percentage_usage_per_song: pd.Series):\n",
    "    return len(percentage_usage_per_song[percentage_usage_per_song > 0])\n",
    "\n",
    "# Function called when the button is clicked\n",
    "def textbox_changed(word: str):\n",
    "    searched_word = word\n",
    "    word_searched = word.lower().strip()\n",
    "\n",
    "    songs_count = songs\n",
    "\n",
    "    songs_count[\"percentage_usage_per_song\"] = songs_count[\"lyrics_keywords\"].map(lambda x: percentage_usage_per_song(word, x))\n",
    "\n",
    "    # We want to calculate the average of the percentage of usage for each years\n",
    "    songs_count[\"average_usage\"] = songs_count[\"percentage_usage_per_song\"].map(lambda x: x.mean())\n",
    "    songs_count[\"number_of_songs\"] = songs_count[\"percentage_usage_per_song\"].map(count_songs)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "    \n",
    "    songs_count.plot.bar(\n",
    "        x=\"year\",\n",
    "        y=\"number_of_songs\",\n",
    "        figsize=(25, 5),\n",
    "        ax=axes[0],\n",
    "        xlabel=\"Année\",\n",
    "        label=\"Nombre de musiques utilisant le mot\"\n",
    "    )\n",
    "\n",
    "    songs_count.plot.bar(\n",
    "        x=\"year\",\n",
    "        y=\"average_usage\",\n",
    "        figsize=(25, 5),\n",
    "        ax=axes[1],\n",
    "        color=(1, 0, 0),\n",
    "        xlabel=\"Année\",\n",
    "        label=\"Moyenne du pourcentage d'utilisation du mot\"\n",
    "    )\n",
    "\n",
    "# Button interaction\n",
    "ipw.interact_manual(textbox_changed, word=word_textbox.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. LIMITATIONS ET PERSPECTIVES\n",
    "\n",
    "La limitation principale de notre projet est évidemment sur l’échantillons de données que nous avons. Pour ce cas d’école, nous avons tout de même une bonne quantité de données pour les statistiques que nous effectuons. Néanmoins en augmentant encore le nombre de chansons de différents artistes de différentes années, les résultats pourraient être encore plus précis. \n",
    "De plus, comme dis précédemment, si on prend un exemple précis de l’affichage de l’utilisation d’un mot par années. Si un artiste utilise un mot un grand nombre de fois cela peut parfois fausser la statistique. \n",
    "\n",
    "L'amélioration la plus intéressante qui pourrait être faite est celle de comparer différents genres musicaux. Comme par exemple, comparer le pourcentage d’utilisation d’un mot particulier dans le rap, rock et la pop. On pourrait également comparer la variété du vocabulaire de différents artistes des différents genres pour voir dans quel style il y a le moins de répétitions de mots. \n",
    "Grâce à notre façon de calculer cette statistique, il nous est aisé de d'appliquer cette amélioration. Il suffirait d’ajouter des chansons de différents styles musicales dans le fichier qui contient tous les titres des musiques et qu’il soit aussi disponible sur le site de Genius.\n",
    "\n",
    "Une autre amélioration envisageable serait de pouvoir ajouter directement une chanson qui sera utilisé dans les statistiques grâce à une interface intégré au notebook. Cela augmentera beaucoup l’utilisation de notre projet pour des utilisateurs moins expérimentés.\n",
    "\n",
    "Malheureusement nous n’avons pas pu réaliser ces fonctionnalités en raison d'un manque de temps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. CONCLUSION\n",
    "\n",
    "En dehors de la problématique de la récupération des paroles de chansons, nous n'avons pas particulièrement rencontré de trop grosses difficultés lors de la réalisation de ce projet. \n",
    "Il nous a permis de nous familiariser avec la « transformation » de données pour les avoir dans le format souhaité. En plus de cela, on a pu avoir une première approche des outils que fournissent le langage python pour réaliser des graphiques. \n",
    "\n",
    "Nous avons pu terminer le travail dans les temps. Toutes les fonctionnalités prévues initialement ont pu être réalisé et quelques ajouts ont également été effectué. Nous aurions aimé pouvoir achever complétement le projet avant de le rendre avec les quelques améliorations citées au-dessus mais nous sommes déjà satisfaits du résultat actuel. \n",
    "\n",
    "Pour conclure, nous espérons que nous avons pu montrer avec genyus et ses différentes statistiques, la variété et même l’évolution du vocabulaire utilisé dans le rap francophone.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <br/>\n",
    "  <img src=\"medias/he-arc-logo.png\" width=\"450px\">\n",
    "  <br/>\n",
    "  <br/>\n",
    "  <p align=\"center\">Haute-École Arc (Tous droits réservés)\n",
    "  </p>\n",
    "  <br/>\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "93ad480a54dfe9bd795c518354d898cb64ee6e6895a3f8c350fb267ef01e64da"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
